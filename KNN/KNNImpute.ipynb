{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee341f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "import h5py\n",
    "import os \n",
    "import math \n",
    "from scipy.spatial import cKDTree\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.feature as cfeature\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e31cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory: str, ftype):\n",
    "    \"\"\"\n",
    "    List files all file in given folder.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Directory to search for files.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are week ranges and values are lists of matching files.\n",
    "    \"\"\"\n",
    "    matching_files = []\n",
    "    matching_files.extend(\n",
    "        [directory+\"/\"+f for f in os.listdir(directory) if f.endswith(ftype)]\n",
    "    )\n",
    "    #files_by_week[f\"{start} to {stop}\"] = matching_files\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "# Function to generate the grid points\n",
    "def generate_grid_points(top_left_lat, top_left_lon, bottom_right_lat, bottom_right_lon, grid_size):\n",
    "    grid_points = []\n",
    "\n",
    "    # Calculate the distance between the top-left and bottom-right corners\n",
    "    lat_distance = abs(top_left_lat - bottom_right_lat)\n",
    "    lon_distance = abs(top_left_lon - bottom_right_lon)\n",
    "\n",
    "    # Calculate the number of grids in latitude and longitude directions\n",
    "    num_lat_grids = int(lat_distance * 111.32 / grid_size)  # 1 degree latitude ~ 111.32 km\n",
    "    num_lon_grids = int(lon_distance * 111.32 * math.cos(math.radians(top_left_lat)) / grid_size)\n",
    "\n",
    "    # Generate grid points\n",
    "    for i in range(num_lat_grids + 1):\n",
    "        for j in range(num_lon_grids + 1):\n",
    "            lat = top_left_lat - (i * grid_size / 111.32)\n",
    "            lon = top_left_lon + (j * grid_size / (111.32 * math.cos(math.radians(top_left_lat))))\n",
    "            grid_points.append((lat, lon))\n",
    "\n",
    "    return grid_points\n",
    "\n",
    "def load_combined_file(file_path):\n",
    "    \"\"\"\n",
    "    Load the combined HDF5 file and extract the data.\n",
    "    \"\"\"\n",
    "    print(file_path)\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        soil_moisture = f['soil_moisture'][:]\n",
    "        latitude = f['latitude'][:]\n",
    "        longitude = f['longitude'][:]\n",
    "    \n",
    "    #print(soil_moisture)\n",
    "    \n",
    "    \"\"\"\n",
    "    plot_on_map(\n",
    "        latitude,\n",
    "        longitude,\n",
    "        soil_moisture,\n",
    "        [4.5, 25.5, 95.5, 110.5],\n",
    "        #p_name,\n",
    "        title=\"\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    return soil_moisture, latitude, longitude\n",
    "\n",
    "def ReadData(csv_file, lat, lon):\n",
    "    # Determine the bounding box of the SMAP data\n",
    "    lat_min, lat_max = min(lat), max(lat)\n",
    "    lon_min, lon_max = min(lon), max(lon)\n",
    "    \n",
    "    # Load telemetry station data (CSV format assumed)\n",
    "    #tele_data = pd.read_csv(csv_file, names=['code','latitude','longitude','val'])\n",
    "    tele_data = pd.read_csv(csv_file)\n",
    "    #print(tele_data)\n",
    "    \n",
    "    # Filter telemetry stations within SMAP bounding box\n",
    "    filtered_stations = tele_data[\n",
    "        (tele_data['latitude'] >= lat_min) & (tele_data['latitude'] <= lat_max) &\n",
    "        (tele_data['longitude'] >= lon_min) & (tele_data['longitude'] <= lon_max)\n",
    "    ]\n",
    "    return filtered_stations\n",
    "\n",
    "def genSMAP(filtered_stations, smap_locations, _smapDf, paraName):\n",
    "    tele_locations = filtered_stations[['latitude', 'longitude']].to_numpy()\n",
    "    tele_values = filtered_stations['val'].to_numpy()\n",
    "    \n",
    "    #print(tele_locations, tele_values)\n",
    "    \n",
    "    smap_tree = cKDTree(smap_locations)\n",
    "    \n",
    "    # Keep track of used locations in smapDf\n",
    "    used_smap_indices = set()\n",
    "    \n",
    "    # Prepare a column to store results\n",
    "    _smapDf[paraName] = np.nan  # New column for matched SMAP values\n",
    "    \n",
    "    \n",
    "    # Iterate over each smap location and match it to the nearest tele location\n",
    "    for idx, tele_loc in enumerate(tele_locations):\n",
    "        # Query the nearest tele location\n",
    "        #distance, tele_idx = tele_tree.query(tele_loc)\n",
    "        distance, smap_idx = smap_tree.query(tele_loc)\n",
    "        #print(distance, smap_idx,idx , tele_loc, smap_locations[smap_idx])\n",
    "    \n",
    "        if smap_idx not in used_smap_indices:\n",
    "            _smapDf.loc[smap_idx, paraName] = tele_values[idx]\n",
    "            #print(distance, smap_idx,idx , tele_loc, smap_locations[smap_idx],tele_values[idx], smapDf['matched_smap_val'][idx])\n",
    "            used_smap_indices.add(smap_idx)  # Mark this SMAP index as used\n",
    "    \n",
    "    #print(smapDf)\n",
    "    return _smapDf\n",
    "\n",
    "# IDW Interpolation function\n",
    "def inverse_distance_weighting(x, y, values, xi, yi, power=2):\n",
    "    tree = cKDTree(np.c_[x, y])\n",
    "    distances, indices = tree.query(np.c_[xi.ravel(), yi.ravel()], k=5)\n",
    "    weights = 1 / distances ** power\n",
    "    weighted_values = np.sum(weights * values[indices], axis=1) / np.sum(weights, axis=1)\n",
    "    return weighted_values.reshape(xi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa27ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         latitude   longitude\n",
      "0       18.607933  101.005346\n",
      "1       18.607933  101.014825\n",
      "2       18.607933  101.024303\n",
      "3       18.607933  101.033782\n",
      "4       18.607933  101.043260\n",
      "...           ...         ...\n",
      "269819  14.017563  105.953182\n",
      "269820  14.017563  105.962661\n",
      "269821  14.017563  105.972139\n",
      "269822  14.017563  105.981618\n",
      "269823  14.017563  105.991097\n",
      "\n",
      "[269824 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "EARTH_RADIUS = 6371  # Earth's radius in kilometers\n",
    "grid_size = 1\n",
    "\n",
    "# NorthEast\n",
    "lat_range = [18.607933, 14.012681]  # Define the latitude range of interest\n",
    "lon_range = [101.005346, 105.995516]  # Define the longitude range of interest\n",
    "\n",
    "# Top Left\n",
    "#lat_range = [18.607933, 16.310307]  # Define the latitude range of interest\n",
    "#lon_range = [101.005346, 103.5004]  # Define the longitude range of interest\n",
    "\n",
    "# Bottom Left\n",
    "#lat_range = [16.310307, 14.012681]  # Define the latitude range of interest\n",
    "#lon_range = [101.005346, 103.5004]  # Define the longitude range of interest\n",
    "\n",
    "# Top Right\n",
    "#lat_range = [18.607933, 16.310307]  # Define the latitude range of interest\n",
    "#lon_range = [103.5004, 105.995516]  # Define the longitude range of interest\n",
    "\n",
    "# Bottom Right\n",
    "#lat_range = [16.310307, 14.012681]  # Define the latitude range of interest\n",
    "#lon_range = [103.5004, 105.995516]  # Define the longitude range of interest\n",
    "\n",
    "# Calculate the distance in kilometers\n",
    "#distance_left_2_right = geodesic((lat_range[0], lon_range[0]), (lat_range[0], lon_range[1])).kilometers\n",
    "#distance_top_2_down = geodesic((lat_range[0], lon_range[0]), (lat_range[1], lon_range[0])).kilometers\n",
    "\n",
    "#print(distance_left_2_right)\n",
    "#print(distance_top_2_down)\n",
    "\n",
    "grid_points = generate_grid_points(lat_range[0], lon_range[0], lat_range[1], lon_range[1], grid_size)\n",
    "\n",
    "points = pd.DataFrame(grid_points, columns=['latitude', 'longitude'])\n",
    "print(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3724a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your data files\n",
    "smap_dir = \"C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\\"  # Replace with your .h5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd73560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2022-12-26to2023-01-01.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-01-02to2023-01-08.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-01-09to2023-01-15.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-01-16to2023-01-22.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-01-23to2023-01-29.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-01-30to2023-02-05.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-02-06to2023-02-12.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-02-13to2023-02-19.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-02-20to2023-02-26.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-02-27to2023-03-05.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-03-06to2023-03-12.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-03-13to2023-03-19.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-03-20to2023-03-26.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-03-27to2023-04-02.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-04-03to2023-04-09.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-04-10to2023-04-16.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-04-17to2023-04-23.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-04-24to2023-04-30.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-05-01to2023-05-07.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-05-08to2023-05-14.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-05-15to2023-05-21.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-05-22to2023-05-28.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-05-29to2023-06-04.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-06-05to2023-06-11.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-06-12to2023-06-18.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-06-19to2023-06-25.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-06-26to2023-07-02.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-07-03to2023-07-09.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-07-10to2023-07-16.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-07-17to2023-07-23.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-07-24to2023-07-30.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-07-31to2023-08-06.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-08-07to2023-08-13.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-08-14to2023-08-20.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-08-21to2023-08-27.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-08-28to2023-09-03.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-09-04to2023-09-10.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-09-11to2023-09-17.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-09-18to2023-09-24.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-09-25to2023-10-01.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-10-02to2023-10-08.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-10-09to2023-10-15.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-10-16to2023-10-22.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-10-23to2023-10-29.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-10-30to2023-11-05.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-11-06to2023-11-12.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-11-13to2023-11-19.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-11-20to2023-11-26.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-11-27to2023-12-03.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-12-04to2023-12-10.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-12-11to2023-12-17.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-12-18to2023-12-24.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2023-12-25to2023-12-31.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-01-01to2024-01-07.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-01-08to2024-01-14.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-01-15to2024-01-21.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-01-22to2024-01-28.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-01-29to2024-02-04.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-02-05to2024-02-11.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-02-12to2024-02-18.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-02-19to2024-02-25.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-02-26to2024-03-03.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-03-04to2024-03-10.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-03-11to2024-03-17.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-03-18to2024-03-24.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-03-25to2024-03-31.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-04-01to2024-04-07.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-04-08to2024-04-14.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-04-15to2024-04-21.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-04-22to2024-04-28.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-04-29to2024-05-05.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-05-06to2024-05-12.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-05-13to2024-05-19.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-05-20to2024-05-26.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-05-27to2024-06-02.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-06-03to2024-06-09.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-06-10to2024-06-16.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-06-17to2024-06-23.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-06-24to2024-06-30.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-07-01to2024-07-07.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-07-08to2024-07-14.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-07-15to2024-07-21.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-07-22to2024-07-28.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-07-29to2024-08-04.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-08-05to2024-08-11.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-08-12to2024-08-18.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-08-19to2024-08-25.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-08-26to2024-09-01.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-09-02to2024-09-08.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-09-09to2024-09-15.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-09-16to2024-09-22.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-09-23to2024-09-29.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-09-30to2024-10-06.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-10-07to2024-10-13.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-10-14to2024-10-20.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-10-21to2024-10-27.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-10-28to2024-11-03.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-11-04to2024-11-10.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-11-11to2024-11-17.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-11-18to2024-11-24.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-11-25to2024-12-01.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-12-02to2024-12-08.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-12-09to2024-12-15.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-12-16to2024-12-22.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-12-23to2024-12-29.h5', 'C:\\\\Work\\\\Code\\\\SMAP\\\\Weekly\\\\Thailand\\\\/2024-12-30to2024-12-31.h5']\n"
     ]
    }
   ],
   "source": [
    "h5_files = list_files(smap_dir,'.h5')\n",
    "print(h5_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a04d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269824\n",
      "C:\\Work\\Code\\SMAP\\Weekly\\Thailand\\/2022-12-26to2023-01-01.h5\n"
     ]
    }
   ],
   "source": [
    "# Build a KDTree for smapDf locations\n",
    "smap_locations = points[['latitude', 'longitude']].to_numpy()\n",
    "print(len(smap_locations))\n",
    "\n",
    "lenLat = len(points['latitude'].unique())\n",
    "lenLon = len(points['longitude'].unique())\n",
    "\n",
    "# Create a grid for interpolation\n",
    "lat_grid = np.linspace(points['latitude'].min(), points['latitude'].max(), lenLat)\n",
    "lon_grid = np.linspace(points['longitude'].min(), points['longitude'].max(), lenLon)\n",
    "grid_lat, grid_lon = np.meshgrid(lat_grid, lon_grid)\n",
    "\n",
    "for combined_file in h5_files:\n",
    "    #print(combined_file)\n",
    "    soil_moisture, latitude, longitude = load_combined_file(combined_file)\n",
    "    soil_moisture = np.ma.masked_invalid(soil_moisture)\n",
    "    p_name = combined_file.replace(smap_dir+\"/\",\"\")\n",
    "    p_name = p_name.replace(\".h5\",\"\")\n",
    "    p_name = p_name[:10].replace(\"-\",\"\")\n",
    "    #print(p_name)\n",
    "    \n",
    "    \"\"\"\n",
    "    humidDf= ReadData(tele_humid_dir+p_name+\".csv\", latitude, longitude)\n",
    "    humidDf = humidDf.reset_index(drop=True)\n",
    "    #print(humidDf)\n",
    "    \n",
    "    tempDf= ReadData(tele_temp_dir+p_name+\".csv\", latitude, longitude)\n",
    "    tempDf = tempDf.reset_index(drop=True)\n",
    "    #print(tempDf)\n",
    "    \n",
    "    rainDf= ReadData(tele_rain_dir+p_name+\".csv\", latitude, longitude)\n",
    "    rainDf = rainDf.reset_index(drop=True)\n",
    "    #print(rainDf)    \n",
    "    \"\"\"\n",
    "    \n",
    "    smapDf = pd.DataFrame(columns=['latitude','longitude','val'])\n",
    "    smapDf['latitude'] = latitude\n",
    "    smapDf['longitude'] = longitude\n",
    "    smapDf['val'] = soil_moisture\n",
    "    \n",
    "    #print(smapDf[:10])\n",
    "    \n",
    "    smapDf = genSMAP(smapDf, smap_locations, points, \"val\")\n",
    "    \n",
    "    #print(len(humidDf['latitude']))\n",
    "    #break\n",
    "    \"\"\"\n",
    "    # Applying IDW to interpolate rain data on grid\n",
    "    humid_idw = inverse_distance_weighting(\n",
    "        humidDf['latitude'].values,\n",
    "        humidDf['longitude'].values,\n",
    "        humidDf['val'].values,\n",
    "        grid_lat,\n",
    "        grid_lon\n",
    "    )\n",
    "    \"\"\"\n",
    "    #smapDf['humid'] = humid_idw.reshape(1,-1)[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c6dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         latitude   longitude     val\n",
      "0       18.607933  101.005346     NaN\n",
      "1       18.607933  101.014825     NaN\n",
      "2       18.607933  101.024303     NaN\n",
      "3       18.607933  101.033782     NaN\n",
      "4       18.607933  101.043260     NaN\n",
      "...           ...         ...     ...\n",
      "269819  14.017563  105.953182  0.1370\n",
      "269820  14.017563  105.962661  0.1450\n",
      "269821  14.017563  105.972139  0.0740\n",
      "269822  14.017563  105.981618  0.1100\n",
      "269823  14.017563  105.991097  0.1505\n",
      "\n",
      "[269824 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(smapDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeaf1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KNN Imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "df_imputed = pd.DataFrame(knn_imputer.fit_transform(smapDf), columns=smapDf.columns)\n",
    "\n",
    "print(\"\\nImputed Data:\")\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_bounds = [4.5, 25.5, 95.5, 110.5]\n",
    "\n",
    "# Create the figure and axis\n",
    "projection = ccrs.PlateCarree()\n",
    "fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': projection})\n",
    "\n",
    "# Set the map extent to Thailand\n",
    "min_lat, max_lat, min_lon, max_lon = region_bounds\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=projection)\n",
    "\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "#sc = ax.scatter(test_dfs[0]['longitude'], test_dfs[0]['latitude'], c=test_dfs[0]['val'], cmap='YlGnBu', marker='s', s=5, vmin=0, vmax=1, transform=projection)\n",
    "sc = ax.scatter(df_imputed['longitude'], df_imputed['latitude'], c=df_imputed['val'], cmap='YlGnBu', marker='s', s=5, transform=projection)\n",
    "plt.colorbar(sc, ax=ax, orientation='vertical', label='Predict Soil Moisture')\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f293ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly remove 20% of data\n",
    "num_missing = int(0.5 * len(df_imputed))\n",
    "missing_indices = np.random.choice(len(df_imputed), num_missing, replace=False)\n",
    "df_imputed['remove'] = df_imputed['val']\n",
    "df_imputed['remove'].iloc[missing_indices] = np.nan\n",
    "\n",
    "\n",
    "#df_imputed['remove'] = np.nan\n",
    "#df_imputed['remove'][mask] = np.nan\n",
    "print(df_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(knn_imputed['val'], knn_imputed['remove'])\n",
    "print(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffc850",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f55323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Forest Imputer\n",
    "if df_imputed['val'].isnull().sum() > 0:\n",
    "    train_data = df_imputed[df_imputed['val'].notnull()]\n",
    "    test_data = df_imputed[df_imputed['val'].isnull()]\n",
    "\n",
    "    X_train = train_data.drop(columns=[column])\n",
    "    y_train = train_data[column]\n",
    "    X_test = test_data.drop(columns=[column])\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    df.loc[df[column].isnull(), column] = model.predict(X_test)\n",
    "\n",
    "print(\"\\nImputed Data using Random Forest:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
